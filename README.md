Proje Ã–zetiBu proje, bÃ¼yÃ¼k Ã¶lÃ§ekli ham web sunucusu log verisini etkin bir ÅŸekilde iÅŸlemek, analiz etmek ve gÃ¶rselleÅŸtirmek iÃ§in uÃ§tan uca, daÄŸÄ±tÄ±k bir veri iÅŸleme pipeline'Ä± (borusu) kurmayÄ± amaÃ§lamÄ±ÅŸtÄ±r. Bu Ã§alÄ±ÅŸma, modern Big Data teknolojilerini kullanarak verimlilik, depolama optimizasyonu ve dÃ¼ÅŸÃ¼k gecikmeli eriÅŸim konularÄ±na odaklanmaktadÄ±r.âš™ï¸ Teknik AmaÃ§lar ve BaÅŸarÄ±mlarBaÅŸarÄ±m/HedefKullanÄ±lan TeknolojiSonuÃ§ OdaklÄ± AÃ§Ä±klamaDepolama OptimizasyonuApache Spark (PySpark), Parquet5 milyon satÄ±rlÄ±k (1.2 GB) ham log verisini satÄ±r tabanlÄ± JSON formatÄ±ndan sÃ¼tun tabanlÄ± Parquet formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rerek depolama maliyetinde %75 tasarruf saÄŸlandÄ±.DaÄŸÄ±tÄ±k Veri Ä°ÅŸlemePySparkVeri setinin daÄŸÄ±tÄ±k ortamda hÄ±zlÄ± iÅŸlenmesi saÄŸlandÄ± ve anahtar performans Ã¶lÃ§Ã¼tleri (Okuma/Yazma sÃ¼releri) optimize edildi.Veri GÃ¶rselleÅŸtirmeStreamlitSpark ile iÅŸlenen temizlenmiÅŸ ve analiz edilmiÅŸ verileri kullanarak, interaktif bir web tabanlÄ± izleme ve analiz dashboard'u geliÅŸtirildi.DÃ¼ÅŸÃ¼k Gecikmeli Veri EriÅŸimiHBaseAnaliz sonuÃ§larÄ±, okuma performansÄ±na odaklanmÄ±ÅŸ bir ÅŸema tasarÄ±mÄ±yla HBase NoSQL veritabanÄ±na kaydedilerek anlÄ±k eriÅŸim gerektiren dashboard iÃ§in optimize edildi.Veri AnaliziPySpark, Veri KalitesiProje kapsamÄ±nda, genel servis hata oranÄ± %7.75 olarak hesaplandÄ± ve en hatalÄ± servis olan payment-service tespit edilerek kÃ¶k neden analizi iÃ§in zemin hazÄ±rlandÄ±.ğŸ› ï¸ KullanÄ±lan TeknolojilerBu projenin omurgasÄ±nÄ± oluÅŸturan temel teknolojiler ÅŸunlardÄ±r:Programlama Dili: PythonDaÄŸÄ±tÄ±k Ä°ÅŸleme: Apache Spark (PySpark)Veri Depolama: MinIO (S3 Uyumlu Nesne Depolama), Parquet (SÃ¼tun TabanlÄ± Format)VeritabanÄ±: HBase (NoSQL, GeniÅŸ SÃ¼tunlu)GÃ¶rselleÅŸtirme: StreamlitÃ‡evre: Docker / Docker Compose (Yerel DaÄŸÄ±tÄ±k ortam simÃ¼lasyonu iÃ§in)ğŸ“‚ Proje YapÄ±sÄ±bigdata-log-analysis/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_logs.jsonl
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ spark_analysis.ipynb      # Spark transformasyon ve analiz kodlarÄ±
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ spark_job.py              # PySpark script'i
â”‚   â””â”€â”€ streamlit_app.py          # GÃ¶rselleÅŸtirme uygulamasÄ±
â”œâ”€â”€ docker-compose.yml            # TÃ¼m servislerin (Spark, MinIO, HBase) ayarlarÄ±
â””â”€â”€ README.md                     # Bu dosya
ğŸƒ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r (Kurulum)Depoyu KlonlayÄ±n:Bashgit clone https://github.com/KullaniciAdiniz/bigdata-log-analysis.git
cd bigdata-log-analysis
Docker OrtamÄ±nÄ± BaÅŸlatÄ±n:Bashdocker-compose up -d
Spark Ä°ÅŸini Ã‡alÄ±ÅŸtÄ±rÄ±n:(Ã–rnek komut, Spark konteyneri iÃ§inde Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r.)Bashdocker exec -it spark-master /bin/bash -c "spark-submit /app/src/spark_job.py"
Streamlit Dashboard'u GÃ¶rÃ¼ntÃ¼leyin:TarayÄ±cÄ±nÄ±zda http://localhost:8501 adresine giderek analiz sonuÃ§larÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyebilirsiniz.
